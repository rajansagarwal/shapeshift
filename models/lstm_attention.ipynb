{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from geopy.distance import geodesic\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, concatenate, Activation, dot, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "def load_data(target_lat, target_lon):\n",
    "    data = pd.read_csv('../datasets/all_month.csv')\n",
    "    data.dropna(inplace=True)\n",
    "    data['time'] = pd.to_datetime(data['time']).astype(int) / 1e9\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    data[['time', 'mag', 'depth']] = scaler.fit_transform(data[['time', 'mag', 'depth']].astype(float))\n",
    "    data['distance'] = data.apply(lambda row: geodesic((row['latitude'], row['longitude']), (target_lat, target_lon)).kilometers, axis=1)\n",
    "    \n",
    "    data = data[data['distance'] <= 500]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i+seq_length].astype(np.float32))\n",
    "    return np.array(sequences)\n",
    "\n",
    "def build_model(data, seq_length):\n",
    "    input_sequences = create_sequences(data[['latitude', 'longitude', 'time', 'mag', 'depth']].values, seq_length)\n",
    "    target_sequences = create_sequences(data['distance'].values.reshape(-1, 1), seq_length)\n",
    "    \n",
    "    inputs = Input(shape=(seq_length, 5))\n",
    "\n",
    "    lstm_out = LSTM(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(inputs)\n",
    "    lstm_out = LSTM(64, return_sequences=True, dropout=0.1)(lstm_out)\n",
    "\n",
    "    attention_scores = dot([lstm_out, lstm_out], axes=[2, 2])\n",
    "    attention_scores = Activation('softmax')(attention_scores)\n",
    "\n",
    "    context_vector = dot([attention_scores, lstm_out], axes=[2,1])\n",
    "    context_lstm = concatenate([context_vector, lstm_out])\n",
    "\n",
    "    output = TimeDistributed(Dense(1))(context_lstm)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_logarithmic_error')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_sequences, target_sequences, test_size=0.2, random_state=42)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['validation_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_distance(model, data, seq_length, target_lat, target_lon):\n",
    "    data['time'] = pd.to_datetime(data['time']).astype(int) / 1e9\n",
    "    scaler = MinMaxScaler()\n",
    "    data[['time', 'mag', 'depth']] = scaler.fit_transform(data[['time', 'mag', 'depth']].astype(float))\n",
    "    input_data = data[['latitude', 'longitude', 'time', 'mag', 'depth']].values[-seq_length:].reshape(1, seq_length, 5)\n",
    "    \n",
    "    predicted_distance = model.predict(input_data)\n",
    "    \n",
    "    return predicted_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lat = 31.734\n",
    "in_lon = -118.25\n",
    "data = load_data(in_lat, in_lon)\n",
    "model = build_model(data, seq_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_distances = predict_distance(model, data, 50, in_lat, in_lon)\n",
    "expected_distance = predicted_distances[0][-1][0]\n",
    "print(f\"Predicted Distance: {expected_distance} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "map_center = [in_lat, in_lon]\n",
    "earthquake_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "folium.Circle(\n",
    "    location=map_center,\n",
    "    radius=expected_distance * 1000,\n",
    "    color='blue',\n",
    "    fill=True,\n",
    "    fill_color='blue',\n",
    "    fill_opacity=0.2\n",
    ").add_to(earthquake_map)\n",
    "\n",
    "earthquake_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
